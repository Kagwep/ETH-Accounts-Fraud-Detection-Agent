{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import certifi\n",
    "import os\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "os.environ['SSL_CERT_FILE'] = certifi.where()\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import logging\n",
    "from scipy.ndimage import zoom\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "from giza.datasets import DatasetsLoader, DatasetsHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 32)  # First hidden layer\n",
    "        self.layer2 = nn.Linear(32, 16)          # Second hidden layer\n",
    "        self.output_layer = nn.Linear(16, 1)     # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))              # Activation function for the first hidden layer\n",
    "        x = F.relu(self.layer2(x))              # Activation function for the second hidden layer\n",
    "        x = torch.sigmoid(self.output_layer(x)) # Sigmoid activation for output layer\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('./address_data_combined.csv')\n",
    "X = df.drop(columns=['Address', 'FLAG'])\n",
    "y = df['FLAG']\n",
    "\n",
    "# Define columns to transform\n",
    "columns = ['Avg min between sent tnx', 'Avg min between received tnx',\n",
    "           'Time Diff between first and last (Mins)',\n",
    "           'Unique Received From Addresses', 'min value received',\n",
    "           'max value received ', 'avg val received', 'min val sent',\n",
    "           'avg val sent', 'total transactions (including tnx to create contract',\n",
    "           'total ether received', 'total ether balance']\n",
    "\n",
    "# Log Transformation for Skewed Data\n",
    "for c in columns:\n",
    "    X[c] = X[c].apply(lambda x: np.log(x) if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Transformation for Skewed Data\n",
    "for c in columns:\n",
    "    X[c] = X[c].apply(lambda x: np.log(x) if x > 0 else 0)\n",
    "\n",
    "# Continue with your data preprocessing...\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "X_train_full = scaler.fit_transform(X_train_full)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of X_train_full: <class 'numpy.ndarray'>\n",
      "Shape of X_train_full: (10616, 12)\n",
      "Type of y_train_full: <class 'pandas.core.series.Series'>\n",
      "Shape of y_train_full: (10616,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of X_train_full:\", type(X_train_full))\n",
    "print(\"Shape of X_train_full:\", X_train_full.shape)\n",
    "print(\"Type of y_train_full:\", type(y_train_full))\n",
    "print(\"Shape of y_train_full:\", y_train_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_train_full to a NumPy array if it's a Pandas Series\n",
    "if isinstance(y_train_full, pd.Series):\n",
    "    y_train_full = y_train_full.values  # Convert Series to NumPy array\n",
    "\n",
    "# Now y_train_full is a NumPy array, and you can safely convert it to a tensor\n",
    "train_dataset = TensorDataset(torch.tensor(X_train_full.astype('float32')), torch.tensor(y_train_full.astype('float32')).unsqueeze(1))\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_test and y_test have similar type issues\n",
    "if isinstance(y_test, pd.Series):\n",
    "    y_test = y_test.values\n",
    "\n",
    "test_dataset = TensorDataset(torch.tensor(X_test.astype('float32')), torch.tensor(y_test.astype(\"float32\")).unsqueeze(1))\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size=X_train_full.shape[1])\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss for binary classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.3177\n",
      "Epoch [20/100], Loss: 0.2217\n",
      "Epoch [30/100], Loss: 0.2127\n",
      "Epoch [40/100], Loss: 0.3519\n",
      "Epoch [50/100], Loss: 0.3333\n",
      "Epoch [60/100], Loss: 0.2311\n",
      "Epoch [70/100], Loss: 0.2147\n",
      "Epoch [80/100], Loss: 0.2826\n",
      "Epoch [90/100], Loss: 0.3579\n",
      "Epoch [100/100], Loss: 0.5227\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()      # Clear the gradients\n",
    "        outputs = model(inputs)    # Forward pass: compute the output\n",
    "        loss = criterion(outputs, labels)  # Compute the loss\n",
    "        loss.backward()            # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        optimizer.step()           # Perform a single optimization step (parameter update)\n",
    "\n",
    "    if (epoch+1) % 10 == 0:        # Print loss every 10 epochs\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.53%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        predicted = outputs.round()  # Convert probabilities to 0 or 1\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample input tensor with the appropriate size and data type\n",
    "sample_input = torch.randn(1, X_train_full.shape[1], dtype=torch.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2848,  1.2071, -1.1686,  0.0279,  0.9669, -0.7236,  0.6373,  0.8096,\n",
       "          0.0031,  1.1041,  0.5836, -0.8584]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(\n",
    "    model,                       \n",
    "    sample_input,                 \n",
    "    \"fraud_eth__account_detect_model_nn.onnx\",                 \n",
    "    export_params=True,           \n",
    "    opset_version=10,             \n",
    "    do_constant_folding=True  \n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
